{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Right Threshold values for binary classifcation using ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lets suppose we will take a scenario of a binary classification of A & B in such circumstances we can classify using the probability value of 0 to 1.\n",
    "we will classify as follows, If the value is greater than 0.5 its B else A in common cases we can do that by using 0.5 as a Threshold,\n",
    "but that value is not the correct threshold in every binary classification problem, it will change for each usecase, now we will try to predict the threshold using ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# roc curve and auc score\n",
    "#using the below library we can create the dataset\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#n_samples is no of samples we are considering\n",
    "#n_classes is 2 since we use only two classes for binary classfication\n",
    "#weights is [1,1] since we have to take a balanced dataset if you want you can change but balanced is only prefered for best results\n",
    "X, y = make_classification(n_samples=2000, n_classes=2, weights=[1,1], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into traindata and testdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will apply the dataset on different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc-auc: 1.0\n",
      "RF test roc-auc: 0.9815777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "print('RF train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = rf_model.predict_proba(X_test)\n",
    "print('RF test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [0.97, 0.03],\n",
       "       [0.03, 0.97],\n",
       "       ...,\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [0.36, 0.64]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction percentages\n",
    "#first coloumn gives the probaility of the values to be 1 and second column gives prob of value to be 0\n",
    "#we can consider only one from the two columns and later on we can apply the condition to classify after finding the threshold value\n",
    "ytrain_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic train roc-auc: 0.9863568922694498\n",
      "Logistic test roc-auc: 0.9885777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_classifier=LogisticRegression()\n",
    "log_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = log_classifier.predict_proba(X_train)\n",
    "print('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = log_classifier.predict_proba(X_test)\n",
    "print('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.9975081174960356\n",
      "Adaboost test roc-auc: 0.9826111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_classifier=AdaBoostClassifier()\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = ada_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = ada_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.981670071491109\n",
      "Adaboost test roc-auc: 0.9426111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier=KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = knn_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = knn_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will focus on selecting the best threshold for maximum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the predictions for each sample using all the models and we will append all the results in a list called pred. \n",
    "Then we will calculate the mean of all the  individual sample results from different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test roc-auc: 0.9846777777777779\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for model in [rf_model,log_classifier,ada_classifier,knn_classifier]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))\n",
    "final_prediction=pd.concat(pred,axis=1).mean(axis=1)\n",
    "print('Ensemble test roc-auc: {}'.format(roc_auc_score(y_test,final_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=pd.concat(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_model</th>\n",
       "      <th>log_classifier</th>\n",
       "      <th>ada_classifier</th>\n",
       "      <th>knn_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.559186</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.463282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.538202</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.509875</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.779443</td>\n",
       "      <td>0.490344</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.461121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.441377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>0.532403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.441720</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rf_model  log_classifier  ada_classifier  knn_classifier\n",
       "0        0.99        0.991861        0.559186             1.0\n",
       "1        0.01        0.000008        0.463282             0.0\n",
       "2        0.96        0.966929        0.538202             0.8\n",
       "3        0.94        0.761539        0.509875             0.8\n",
       "4        0.57        0.779443        0.490344             0.4\n",
       "..        ...             ...             ...             ...\n",
       "595      0.00        0.024239        0.461121             0.0\n",
       "596      0.02        0.000003        0.441377             0.0\n",
       "597      1.00        0.984385        0.532403             1.0\n",
       "598      0.01        0.001147        0.441720             0.2\n",
       "599      1.00        0.989540        0.559890             0.8\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.columns=['rf_model','log_classifier','ada_classifier','knn_classifier']\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.877762\n",
       "1      0.118323\n",
       "2      0.821283\n",
       "3      0.755353\n",
       "4      0.564947\n",
       "         ...   \n",
       "595    0.123840\n",
       "596    0.115345\n",
       "597    0.876697\n",
       "598    0.160717\n",
       "599    0.837357\n",
       "Length: 600, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91188114, 0.91188114, 0.90158893, 0.90077475, 0.80306516,\n",
       "       0.8030558 , 0.79631489, 0.79412833, 0.78317698, 0.78071156,\n",
       "       0.75545305, 0.75537124, 0.71369595, 0.70893711, 0.70013034,\n",
       "       0.69887362, 0.6717442 , 0.66993537, 0.59712652, 0.59300386,\n",
       "       0.5871569 , 0.58175354, 0.56845371, 0.56736186, 0.54542732,\n",
       "       0.52889283, 0.51115858, 0.48366892, 0.45990225, 0.43222765,\n",
       "       0.4296034 , 0.38405357, 0.37879719, 0.34933098, 0.34336612,\n",
       "       0.24599466, 0.24140421, 0.21102808, 0.20848417, 0.12801207,\n",
       "       0.1278351 , 0.10632697])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Calculate the ROc Curve\n",
    "#now by using the above thresholds we are going to test on y_test\n",
    "#output will be 3 values false +ve rate, true +ve rate, thresholds\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, final_prediction)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have got the threshold values but we dont know which threshold value to consider \n",
    "#for that we will consider each threshold value and will compare the final_prediction value with threshold value\n",
    "#if the final_prediction value is greater the threshold value then consider the output as 1 and store in y_pred\n",
    "#then compare the y_test and y_pred and calculate the accuracy score and append the output to accuracy_ls\n",
    "#now we will create a dataframe for two cols thresholds and accuarcy_ls as print the accuracy for each threshold value\n",
    "#we will select the threshold value with the highest accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(final_prediction>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.432228</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.459902</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.528893</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.545427</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.429603</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.511159</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.567362</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.568454</td>\n",
       "      <td>0.951667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.597127</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.593004</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.587157</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.384054</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.378797</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.349331</td>\n",
       "      <td>0.938333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.343366</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.669935</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.671744</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.698874</td>\n",
       "      <td>0.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.700130</td>\n",
       "      <td>0.921667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.708937</td>\n",
       "      <td>0.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.713696</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.241404</td>\n",
       "      <td>0.881667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.245995</td>\n",
       "      <td>0.881667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.755371</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.755453</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.211028</td>\n",
       "      <td>0.848333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.208484</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.780712</td>\n",
       "      <td>0.838333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.783177</td>\n",
       "      <td>0.836667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794128</td>\n",
       "      <td>0.818333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.796315</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803056</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.127835</td>\n",
       "      <td>0.701667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900775</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901589</td>\n",
       "      <td>0.518333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.106327</td>\n",
       "      <td>0.501667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.911881</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.911881</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "29    0.432228  0.960000\n",
       "28    0.459902  0.960000\n",
       "25    0.528893  0.960000\n",
       "24    0.545427  0.960000\n",
       "30    0.429603  0.958333\n",
       "27    0.483669  0.958333\n",
       "26    0.511159  0.958333\n",
       "23    0.567362  0.953333\n",
       "22    0.568454  0.951667\n",
       "21    0.581754  0.946667\n",
       "18    0.597127  0.946667\n",
       "19    0.593004  0.946667\n",
       "20    0.587157  0.945000\n",
       "31    0.384054  0.941667\n",
       "32    0.378797  0.940000\n",
       "33    0.349331  0.938333\n",
       "34    0.343366  0.936667\n",
       "17    0.669935  0.935000\n",
       "16    0.671744  0.933333\n",
       "15    0.698874  0.923333\n",
       "14    0.700130  0.921667\n",
       "13    0.708937  0.918333\n",
       "12    0.713696  0.916667\n",
       "36    0.241404  0.881667\n",
       "35    0.245995  0.881667\n",
       "11    0.755371  0.866667\n",
       "10    0.755453  0.865000\n",
       "37    0.211028  0.848333\n",
       "38    0.208484  0.846667\n",
       "9     0.780712  0.838333\n",
       "8     0.783177  0.836667\n",
       "7     0.794128  0.818333\n",
       "6     0.796315  0.816667\n",
       "5     0.803056  0.810000\n",
       "4     0.803065  0.808333\n",
       "39    0.128012  0.703333\n",
       "40    0.127835  0.701667\n",
       "3     0.900775  0.520000\n",
       "2     0.901589  0.518333\n",
       "41    0.106327  0.501667\n",
       "1     0.911881  0.500000\n",
       "0     1.911881  0.500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AS you can see the plotted curve is covering most of the region\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
