{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shkatta\\python_anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:\\\\Users\\\\shkatta\\\\Desktop\\\\AI\\\\csv files\\\\red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16664562e-16 -3.05550043e-17 -8.47206937e-17 -2.22218213e-17\n",
      "  1.94440936e-17 -6.38877362e-17 -4.16659149e-18 -1.20753377e-13\n",
      " -8.70817622e-16 -4.08325966e-16 -1.17220107e-15]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02776704,  0.02592492, -0.03078587, -0.03137977, -0.00471876,\n",
       "       -0.04413827, -0.02414174, -0.00293273, -0.00467444, -0.10894663,\n",
       "        0.01043391])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled.mean(axis=0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02160495, 1.00135689, 0.97456598, 0.91099054, 0.86716698,\n",
       "       0.94193125, 1.03673213, 1.03145119, 0.95734849, 0.83829505,\n",
       "       1.0286218 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('randomforestregressor',\n",
       "   RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                         max_features='auto', max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=None,\n",
       "                         verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': None,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'randomforestregressor__max_depth': [None, 5, 3, 1],\n",
       "                         'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 'log2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'randomforestregressor__max_depth': [None, 5, 3, 1],\n",
       "                         'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 'log2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46854458502330654"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3429340625"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential([Dense(6,input_shape=(11,),activation='relu'),\n",
    "                      Dense(1,activation='tanh')])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1279/1279 [==============================] - 1s 665us/step - loss: 25.6378 - accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "1279/1279 [==============================] - 0s 95us/step - loss: 22.2177 - accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1812 - accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "1279/1279 [==============================] - 0s 108us/step - loss: 22.1687 - accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1607 - accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1577 - accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1573 - accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "1279/1279 [==============================] - 0s 101us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "1279/1279 [==============================] - 0s 109us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "1279/1279 [==============================] - 0s 102us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "1279/1279 [==============================] - 0s 88us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "1279/1279 [==============================] - 0s 111us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "1279/1279 [==============================] - 0s 115us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "1279/1279 [==============================] - 0s 148us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "1279/1279 [==============================] - 0s 123us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "1279/1279 [==============================] - 0s 130us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "1279/1279 [==============================] - 0s 133us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "1279/1279 [==============================] - 0s 134us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "1279/1279 [==============================] - 0s 139us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "1279/1279 [==============================] - 0s 141us/step - loss: 22.1572 - accuracy: 0.0000e+00 0s - loss: 22.1299 - accuracy: 0.0000e+0\n",
      "Epoch 24/400\n",
      "1279/1279 [==============================] - 0s 189us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "1279/1279 [==============================] - 0s 144us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "1279/1279 [==============================] - 0s 143us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "1279/1279 [==============================] - 0s 115us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "1279/1279 [==============================] - 0s 94us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "1279/1279 [==============================] - 0s 130us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "1279/1279 [==============================] - 0s 142us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "1279/1279 [==============================] - 0s 99us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "1279/1279 [==============================] - 0s 176us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "1279/1279 [==============================] - 0s 156us/step - loss: 22.1572 - accuracy: 0.0000e+00 0s - loss: 21.7613 - accuracy: 0.0000e+\n",
      "Epoch 34/400\n",
      "1279/1279 [==============================] - 0s 150us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "1279/1279 [==============================] - 0s 98us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "1279/1279 [==============================] - 0s 110us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "1279/1279 [==============================] - 0s 116us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "1279/1279 [==============================] - 0s 139us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "1279/1279 [==============================] - 0s 94us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "1279/1279 [==============================] - 0s 105us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "1279/1279 [==============================] - 0s 91us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "1279/1279 [==============================] - 0s 128us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "1279/1279 [==============================] - 0s 171us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "1279/1279 [==============================] - 0s 147us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "1279/1279 [==============================] - 0s 104us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "1279/1279 [==============================] - 0s 105us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "1279/1279 [==============================] - 0s 107us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "1279/1279 [==============================] - 0s 134us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "1279/1279 [==============================] - 0s 161us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "1279/1279 [==============================] - 0s 108us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "1279/1279 [==============================] - 0s 106us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "1279/1279 [==============================] - 0s 137us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "1279/1279 [==============================] - 0s 98us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "1279/1279 [==============================] - 0s 105us/step - loss: 22.1572 - accuracy: 0.0000e+00 0s - loss: 21.7636 - accuracy: 0.0000e+\n",
      "Epoch 55/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "1279/1279 [==============================] - 0s 95us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "1279/1279 [==============================] - 0s 92us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "1279/1279 [==============================] - 0s 132us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "1279/1279 [==============================] - 0s 181us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "1279/1279 [==============================] - 0s 101us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "1279/1279 [==============================] - 0s 128us/step - loss: 22.1572 - accuracy: 0.0000e+00 0s - loss: 22.1383 - accuracy: 0.0000e+\n",
      "Epoch 66/400\n",
      "1279/1279 [==============================] - 0s 112us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "1279/1279 [==============================] - 0s 113us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "1279/1279 [==============================] - 0s 133us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "1279/1279 [==============================] - 0s 116us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "1279/1279 [==============================] - 0s 86us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "1279/1279 [==============================] - 0s 106us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "1279/1279 [==============================] - 0s 88us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "1279/1279 [==============================] - 0s 101us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "1279/1279 [==============================] - 0s 131us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "1279/1279 [==============================] - 0s 91us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "1279/1279 [==============================] - 0s 120us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "1279/1279 [==============================] - 0s 104us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "1279/1279 [==============================] - 0s 82us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "1279/1279 [==============================] - 0s 138us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "1279/1279 [==============================] - 0s 89us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "1279/1279 [==============================] - 0s 122us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "1279/1279 [==============================] - 0s 136us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "1279/1279 [==============================] - 0s 92us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "1279/1279 [==============================] - 0s 108us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "1279/1279 [==============================] - 0s 130us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "1279/1279 [==============================] - 0s 110us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "1279/1279 [==============================] - 0s 91us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "1279/1279 [==============================] - 0s 129us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "1279/1279 [==============================] - 0s 101us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "1279/1279 [==============================] - 0s 126us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "1279/1279 [==============================] - 0s 117us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "1279/1279 [==============================] - 0s 118us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "1279/1279 [==============================] - 0s 112us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "1279/1279 [==============================] - 0s 140us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "1279/1279 [==============================] - 0s 130us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "1279/1279 [==============================] - 0s 112us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "1279/1279 [==============================] - 0s 147us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "1279/1279 [==============================] - 0s 92us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "1279/1279 [==============================] - 0s 131us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "1279/1279 [==============================] - 0s 115us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "1279/1279 [==============================] - 0s 133us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "1279/1279 [==============================] - 0s 119us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "1279/1279 [==============================] - 0s 103us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "1279/1279 [==============================] - 0s 171us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "1279/1279 [==============================] - 0s 108us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "1279/1279 [==============================] - 0s 151us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "1279/1279 [==============================] - 0s 96us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "1279/1279 [==============================] - 0s 86us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "1279/1279 [==============================] - 0s 153us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "1279/1279 [==============================] - 0s 116us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "1279/1279 [==============================] - 0s 81us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "1279/1279 [==============================] - 0s 87us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "1279/1279 [==============================] - 0s 86us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "1279/1279 [==============================] - 0s 93us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "1279/1279 [==============================] - 0s 86us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "1279/1279 [==============================] - 0s 92us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "1279/1279 [==============================] - 0s 86us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "1279/1279 [==============================] - 0s 87us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "1279/1279 [==============================] - 0s 81us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "1279/1279 [==============================] - 0s 115us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "1279/1279 [==============================] - 0s 119us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "1279/1279 [==============================] - 0s 87us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "1279/1279 [==============================] - 0s 94us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "1279/1279 [==============================] - 0s 89us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 146/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "1279/1279 [==============================] - 0s 72us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "1279/1279 [==============================] - 0s 98us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "1279/1279 [==============================] - 0s 98us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "1279/1279 [==============================] - 0s 106us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "1279/1279 [==============================] - 0s 134us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "1279/1279 [==============================] - 0s 102us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "1279/1279 [==============================] - 0s 82us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "1279/1279 [==============================] - 0s 90us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "1279/1279 [==============================] - 0s 109us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "1279/1279 [==============================] - 0s 108us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "1279/1279 [==============================] - 0s 87us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "1279/1279 [==============================] - 0s 89us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 292/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "1279/1279 [==============================] - 0s 82us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "1279/1279 [==============================] - 0s 88us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "1279/1279 [==============================] - 0s 100us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "1279/1279 [==============================] - 0s 83us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "1279/1279 [==============================] - 0s 82us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "1279/1279 [==============================] - 0s 82us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "1279/1279 [==============================] - 0s 115us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "1279/1279 [==============================] - 0s 145us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "1279/1279 [==============================] - 0s 101us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "1279/1279 [==============================] - 0s 84us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "1279/1279 [==============================] - 0s 85us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "1279/1279 [==============================] - 0s 91us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "1279/1279 [==============================] - 0s 97us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "1279/1279 [==============================] - 0s 79us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "1279/1279 [==============================] - 0s 80us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "1279/1279 [==============================] - 0s 78us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "1279/1279 [==============================] - 0s 75us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "1279/1279 [==============================] - 0s 76us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "1279/1279 [==============================] - 0s 74us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "1279/1279 [==============================] - 0s 77us/step - loss: 22.1572 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22f09e67f60>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,batch_size=10,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
